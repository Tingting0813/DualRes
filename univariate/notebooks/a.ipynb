{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 时间序列预测实验 Notebook\n",
    "\n",
    "这个notebook用于：\n",
    "- 快速测试和调试代码\n",
    "- 探索性数据分析\n",
    "- 实验新的模型和方法\n",
    "- 可视化和结果分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境设置完成！\n"
     ]
    }
   ],
   "source": [
    "# 添加项目根目录到Python路径\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# 基础导入\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置matplotlib参数\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"环境设置完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载配置和初始化组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MeanModel' from 'src.models.mean_model' (/zhangyunyi/code/DualRes/univariate/src/models/mean_model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 导入项目模块\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmean_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MeanModel\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlog_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogModel\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainer\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MeanModel' from 'src.models.mean_model' (/zhangyunyi/code/DualRes/univariate/src/models/mean_model.py)"
     ]
    }
   ],
   "source": [
    "# 导入项目模块\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.models.mean_model import MeanModel\n",
    "from src.models.log_model import LogModel\n",
    "from src.training.trainer import Trainer\n",
    "from src.evaluation.evaluator import ModelEvaluator\n",
    "\n",
    "# 加载配置\n",
    "config_path = '../config/config.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"配置加载成功！\")\n",
    "print(f\"数据集: {config['dataset']['name']}\")\n",
    "print(f\"Mean Model - 上下文长度: {config['mean_model']['context_length']}, 预测长度: {config['mean_model']['prediction_length']}\")\n",
    "print(f\"Log Model - 上下文长度: {config['log_model']['context_length']}, 预测长度: {config['log_model']['prediction_length']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化组件\n",
    "data_loader = DataLoader(config)\n",
    "mean_model = MeanModel(config)\n",
    "log_model = LogModel(config)\n",
    "trainer = Trainer(config, data_loader, mean_model, log_model)\n",
    "evaluator = ModelEvaluator(config)\n",
    "\n",
    "print(\"组件初始化完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data_loader.load_dataset()\n",
    "dataset_info = data_loader.get_dataset_info()\n",
    "\n",
    "print(\"数据集信息：\")\n",
    "for key, value in dataset_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化数据样本\n",
    "from gluonts.dataset.util import to_pandas\n",
    "\n",
    "# 获取第一个时间序列\n",
    "train_entry = data_loader.train_data[0]\n",
    "test_entry = data_loader.test_data[0]\n",
    "\n",
    "# 转换为pandas Series\n",
    "train_series = to_pandas(train_entry, freq=config['dataset']['freq'])\n",
    "test_series = to_pandas(test_entry, freq=config['dataset']['freq'])\n",
    "\n",
    "# 绘图\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(train_series, label='Train', color='blue', alpha=0.7)\n",
    "axes[0].set_title(f\"Training Data - Series {train_entry['item_id']}\")\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(test_series, label='Test', color='green', alpha=0.7)\n",
    "axes[1].set_title(f\"Test Data - Series {test_entry['item_id']}\")\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"训练序列长度: {len(train_series)}\")\n",
    "print(f\"测试序列长度: {len(test_series)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据统计分析\n",
    "train_values = [entry['target'] for entry in data_loader.train_data]\n",
    "train_flat = np.concatenate(train_values)\n",
    "\n",
    "print(\"训练数据统计：\")\n",
    "print(f\"  总数据点: {len(train_flat):,}\")\n",
    "print(f\"  均值: {np.mean(train_flat):.4f}\")\n",
    "print(f\"  标准差: {np.std(train_flat):.4f}\")\n",
    "print(f\"  最小值: {np.min(train_flat):.4f}\")\n",
    "print(f\"  最大值: {np.max(train_flat):.4f}\")\n",
    "print(f\"  25%分位数: {np.percentile(train_flat, 25):.4f}\")\n",
    "print(f\"  50%分位数: {np.percentile(train_flat, 50):.4f}\")\n",
    "print(f\"  75%分位数: {np.percentile(train_flat, 75):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mean Model 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查是否已有训练好的模型\n",
    "model_exists = os.path.exists(mean_model.model_path)\n",
    "print(f\"Mean Model 是否已存在: {model_exists}\")\n",
    "\n",
    "if model_exists:\n",
    "    print(f\"模型路径: {mean_model.model_path}\")\n",
    "    # 加载已有模型\n",
    "    mean_model.load_predictor()\n",
    "    print(\"模型加载成功！\")\n",
    "else:\n",
    "    print(\"需要训练新模型\")\n",
    "    # 训练模型\n",
    "    mean_model.train(data_loader.train_data[:10])  # 使用部分数据快速测试\n",
    "    print(\"模型训练完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速预测测试\n",
    "from gluonts.evaluation import make_evaluation_predictions\n",
    "\n",
    "# 使用前3个时间序列进行快速测试\n",
    "test_subset = data_loader.test_data[:3]\n",
    "\n",
    "forecasts, tss = mean_model.predict(test_subset, num_samples=1)\n",
    "\n",
    "# 可视化预测结果\n",
    "for i in range(min(3, len(forecasts))):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # 真实值\n",
    "    tss[i][-100:].plot(label='True values', color='blue')\n",
    "    \n",
    "    # 预测值\n",
    "    pred_index = pd.date_range(\n",
    "        start=forecasts[i].start_date.to_timestamp(),\n",
    "        periods=len(forecasts[i].mean),\n",
    "        freq=config['dataset']['freq']\n",
    "    )\n",
    "    forecast_series = pd.Series(forecasts[i].mean, index=pred_index)\n",
    "    forecast_series.plot(label='Prediction', color='red', marker='.')\n",
    "    \n",
    "    plt.title(f'Mean Model Prediction - Series {i}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 滑动窗口预测分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查滑动窗口预测结果\n",
    "mean_pred_path = os.path.join(config['paths']['predictions_dir'], \"mean_predictions_value.npy\")\n",
    "\n",
    "if os.path.exists(mean_pred_path):\n",
    "    mean_predictions = np.load(mean_pred_path, allow_pickle=True)\n",
    "    print(f\"滑动窗口预测已加载\")\n",
    "    print(f\"预测形状: {[len(p) for p in mean_predictions[:5]]}\")\n",
    "else:\n",
    "    print(\"生成滑动窗口预测...\")\n",
    "    # 使用少量数据测试\n",
    "    test_data = data_loader.train_data[:5]\n",
    "    mean_predictions = mean_model.sliding_window_prediction(test_data)\n",
    "    print(f\"预测完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析预测误差\n",
    "if 'mean_predictions' in locals():\n",
    "    series_idx = 0\n",
    "    true_values = data_loader.train_data[series_idx]['target']\n",
    "    pred_values = mean_predictions[series_idx]\n",
    "    \n",
    "    # 对齐数据\n",
    "    context_len = config['mean_model']['context_length']\n",
    "    true_aligned = true_values[context_len:context_len+len(pred_values)]\n",
    "    \n",
    "    # 计算误差\n",
    "    errors = np.array(true_aligned) - np.array(pred_values)\n",
    "    \n",
    "    # 绘制误差分布\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # 误差时序图\n",
    "    axes[0].plot(errors[:200], alpha=0.7)\n",
    "    axes[0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[0].set_title('Prediction Errors Over Time')\n",
    "    axes[0].set_xlabel('Time Step')\n",
    "    axes[0].set_ylabel('Error')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 误差直方图\n",
    "    axes[1].hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[1].set_title('Error Distribution')\n",
    "    axes[1].set_xlabel('Error')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"误差统计：\")\n",
    "    print(f\"  均值: {np.mean(errors):.4f}\")\n",
    "    print(f\"  标准差: {np.std(errors):.4f}\")\n",
    "    print(f\"  MAE: {np.mean(np.abs(errors)):.4f}\")\n",
    "    print(f\"  RMSE: {np.sqrt(np.mean(errors**2)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Log Model 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载或计算log-MSE\n",
    "log_mse_path = os.path.join(config['paths']['results_dir'], \n",
    "                            f\"{config['dataset']['name']}_log_mse_losses.csv\")\n",
    "\n",
    "if os.path.exists(log_mse_path):\n",
    "    log_mse_df = pd.read_csv(log_mse_path)\n",
    "    print(\"Log-MSE数据加载成功\")\n",
    "    print(f\"数据形状: {log_mse_df.shape}\")\n",
    "    print(f\"\\n前5行数据：\")\n",
    "    print(log_mse_df.head())\n",
    "else:\n",
    "    print(\"Log-MSE数据不存在，需要先运行完整训练流程\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析log-MSE的自相关性\n",
    "if 'log_mse_df' in locals():\n",
    "    from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "    \n",
    "    # 选择一个时间序列\n",
    "    series_id = 0\n",
    "    series_data = log_mse_df[log_mse_df['series_id'] == series_id]['log_mse'].values\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "    \n",
    "    # 时序图\n",
    "    axes[0, 0].plot(series_data[:500], alpha=0.7)\n",
    "    axes[0, 0].set_title(f'Log-MSE Time Series (Series {series_id})')\n",
    "    axes[0, 0].set_xlabel('Time')\n",
    "    axes[0, 0].set_ylabel('Log-MSE')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 分布图\n",
    "    axes[0, 1].hist(series_data, bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].set_title('Log-MSE Distribution')\n",
    "    axes[0, 1].set_xlabel('Log-MSE')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ACF图\n",
    "    plot_acf(series_data[:1000], lags=50, ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Autocorrelation Function')\n",
    "    \n",
    "    # PACF图\n",
    "    plot_pacf(series_data[:1000], lags=50, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Partial Autocorrelation Function')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Log-MSE统计（Series {series_id}）：\")\n",
    "    print(f\"  均值: {np.mean(series_data):.4f}\")\n",
    "    print(f\"  标准差: {np.std(series_data):.4f}\")\n",
    "    print(f\"  最小值: {np.min(series_data):.4f}\")\n",
    "    print(f\"  最大值: {np.max(series_data):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 最终预测结果分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最终预测结果\n",
    "final_res_path = os.path.join(config['paths']['predictions_dir'], \"final_res_tensor.npy\")\n",
    "\n",
    "if os.path.exists(final_res_path):\n",
    "    final_res = np.load(final_res_path)\n",
    "    print(f\"最终预测结果加载成功\")\n",
    "    print(f\"结果形状: {final_res.shape}\")\n",
    "    print(f\"  采样数: {final_res.shape[0]}\")\n",
    "    print(f\"  时间序列数: {final_res.shape[1]}\")\n",
    "    print(f\"  预测长度: {final_res.shape[2]}\")\n",
    "else:\n",
    "    print(\"最终预测结果不存在，需要先运行预测流程\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析预测不确定性\n",
    "if 'final_res' in locals():\n",
    "    series_idx = 0\n",
    "    samples = final_res[:, series_idx, :]\n",
    "    \n",
    "    # 计算统计量\n",
    "    mean_pred = np.mean(samples, axis=0)\n",
    "    std_pred = np.std(samples, axis=0)\n",
    "    p5 = np.percentile(samples, 5, axis=0)\n",
    "    p25 = np.percentile(samples, 25, axis=0)\n",
    "    p75 = np.percentile(samples, 75, axis=0)\n",
    "    p95 = np.percentile(samples, 95, axis=0)\n",
    "    \n",
    "    # 绘制不确定性\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    x = np.arange(len(mean_pred))\n",
    "    \n",
    "    # 预测和置信区间\n",
    "    axes[0].plot(x, mean_pred, 'b-', label='Mean Prediction')\n",
    "    axes[0].fill_between(x, p5, p95, alpha=0.2, color='blue', label='90% CI')\n",
    "    axes[0].fill_between(x, p25, p75, alpha=0.3, color='blue', label='50% CI')\n",
    "    axes[0].set_title(f'Prediction with Confidence Intervals (Series {series_idx})')\n",
    "    axes[0].set_xlabel('Prediction Step')\n",
    "    axes[0].set_ylabel('Value')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 标准差随时间变化\n",
    "    axes[1].plot(x, std_pred, 'r-', linewidth=2)\n",
    "    axes[1].set_title('Prediction Uncertainty (Standard Deviation)')\n",
    "    axes[1].set_xlabel('Prediction Step')\n",
    "    axes[1].set_ylabel('Std Dev')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"不确定性分析：\")\n",
    "    print(f\"  平均标准差: {np.mean(std_pred):.4f}\")\n",
    "    print(f\"  最小标准差: {np.min(std_pred):.4f} (步骤 {np.argmin(std_pred)})\")\n",
    "    print(f\"  最大标准差: {np.max(std_pred):.4f} (步骤 {np.argmax(std_pred)})\")\n",
    "    print(f\"  标准差增长率: {(std_pred[-1] - std_pred[0]) / std_pred[0] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 实验新模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验：尝试不同的模型配置\n",
    "from gluonts.torch.model.d_linear import DLinearEstimator\n",
    "from gluonts.torch.model.deepar import DeepAREstimator\n",
    "\n",
    "# 创建不同的模型配置\n",
    "model_configs = [\n",
    "    {\n",
    "        'name': 'DLinear',\n",
    "        'estimator': DLinearEstimator(\n",
    "            prediction_length=24,\n",
    "            context_length=168,  # 一周\n",
    "            trainer_kwargs={\"max_epochs\": 10}\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        'name': 'DeepAR',\n",
    "        'estimator': DeepAREstimator(\n",
    "            prediction_length=24,\n",
    "            context_length=168,\n",
    "            freq=config['dataset']['freq'],\n",
    "            trainer_kwargs={\"max_epochs\": 10}\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"实验模型配置准备完成\")\n",
    "print(f\"待测试模型: {[m['name'] for m in model_configs]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 快速比较不同模型（使用少量数据）\n",
    "from gluonts.evaluation import Evaluator\n",
    "\n",
    "# 使用少量数据进行快速实验\n",
    "train_subset = data_loader.train_data[:10]\n",
    "test_subset = data_loader.test_data[:10]\n",
    "\n",
    "results = []\n",
    "evaluator = Evaluator()\n",
    "\n",
    "for model_config in model_configs:\n",
    "    print(f\"\\n训练 {model_config['name']}...\")\n",
    "    \n",
    "    # 训练\n",
    "    predictor = model_config['estimator'].train(train_subset)\n",
    "    \n",
    "    # 预测\n",
    "    from gluonts.evaluation import make_evaluation_predictions\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_subset,\n",
    "        predictor=predictor,\n",
    "        num_samples=10\n",
    "    )\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "    \n",
    "    # 评估\n",
    "    agg_metrics, _ = evaluator(tss, forecasts)\n",
    "    \n",
    "    results.append({\n",
    "        'model': model_config['name'],\n",
    "        'RMSE': agg_metrics['RMSE'],\n",
    "        'MAPE': agg_metrics['MAPE'],\n",
    "        'sMAPE': agg_metrics['sMAPE']\n",
    "    })\n",
    "    \n",
    "    print(f\"  RMSE: {agg_metrics['RMSE']:.4f}\")\n",
    "    print(f\"  MAPE: {agg_metrics['MAPE']:.4f}\")\n",
    "\n",
    "# 结果对比\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n模型性能对比：\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 自定义实验区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里可以添加你自己的实验代码\n",
    "# 例如：测试新的特征工程方法、新的模型架构等\n",
    "\n",
    "print(\"自定义实验区域 - 在这里添加你的实验代码\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 保存实验结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存实验结果\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "experiment_results = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'dataset': config['dataset']['name'],\n",
    "    'mean_model_config': config['mean_model'],\n",
    "    'log_model_config': config['log_model'],\n",
    "    'results': {}\n",
    "}\n",
    "\n",
    "# 如果有评估结果，添加到实验记录\n",
    "if 'results_df' in locals():\n",
    "    experiment_results['results']['model_comparison'] = results_df.to_dict('records')\n",
    "\n",
    "# 保存到文件\n",
    "exp_dir = '../res/experiments/'\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "exp_filename = f\"experiment_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "exp_path = os.path.join(exp_dir, exp_filename)\n",
    "\n",
    "with open(exp_path, 'w') as f:\n",
    "    json.dump(experiment_results, f, indent=2)\n",
    "\n",
    "print(f\"实验结果已保存到: {exp_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "这个notebook提供了以下功能：\n",
    "\n",
    "1. **快速测试**: 可以快速测试项目中的各个模块\n",
    "2. **数据探索**: 可视化和分析数据集\n",
    "3. **模型调试**: 逐步调试模型训练和预测过程\n",
    "4. **结果分析**: 详细分析预测结果和不确定性\n",
    "5. **实验对比**: 比较不同模型配置的性能\n",
    "6. **可视化**: 生成各种图表帮助理解模型行为\n",
    "\n",
    "使用提示：\n",
    "- 修改配置文件后，重新运行第2节的代码块重新加载配置\n",
    "- 可以使用部分数据进行快速实验，避免长时间等待\n",
    "- 所有实验结果会自动保存，方便后续分析"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluonts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
